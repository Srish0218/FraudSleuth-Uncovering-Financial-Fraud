{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:15:44.745517900Z",
     "start_time": "2024-05-18T11:15:39.818309400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n\n      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n0  M1979787155             0.0             0.0        0               0  \n1  M2044282225             0.0             0.0        0               0  \n2   C553264065             0.0             0.0        1               0  \n3    C38997010         21182.0             0.0        1               0  \n4  M1230701703             0.0             0.0        0               0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>step</th>\n      <th>type</th>\n      <th>amount</th>\n      <th>nameOrig</th>\n      <th>oldbalanceOrg</th>\n      <th>newbalanceOrig</th>\n      <th>nameDest</th>\n      <th>oldbalanceDest</th>\n      <th>newbalanceDest</th>\n      <th>isFraud</th>\n      <th>isFlaggedFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>9839.64</td>\n      <td>C1231006815</td>\n      <td>170136.0</td>\n      <td>160296.36</td>\n      <td>M1979787155</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>1864.28</td>\n      <td>C1666544295</td>\n      <td>21249.0</td>\n      <td>19384.72</td>\n      <td>M2044282225</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>TRANSFER</td>\n      <td>181.00</td>\n      <td>C1305486145</td>\n      <td>181.0</td>\n      <td>0.00</td>\n      <td>C553264065</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>CASH_OUT</td>\n      <td>181.00</td>\n      <td>C840083671</td>\n      <td>181.0</td>\n      <td>0.00</td>\n      <td>C38997010</td>\n      <td>21182.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>11668.14</td>\n      <td>C2048537720</td>\n      <td>41554.0</td>\n      <td>29885.86</td>\n      <td>M1230701703</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fraud.csv')                                                             \n",
    "df.head()   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:16:11.561927800Z",
     "start_time": "2024-05-18T11:15:44.727600100Z"
    }
   },
   "id": "2389deafbe72138b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         step      type      amount     nameOrig  oldbalanceOrg  \\\n6362615   743  CASH_OUT   339682.13   C786484425      339682.13   \n6362616   743  TRANSFER  6311409.28  C1529008245     6311409.28   \n6362617   743  CASH_OUT  6311409.28  C1162922333     6311409.28   \n6362618   743  TRANSFER   850002.52  C1685995037      850002.52   \n6362619   743  CASH_OUT   850002.52  C1280323807      850002.52   \n\n         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n6362615             0.0   C776919290            0.00       339682.13        1   \n6362616             0.0  C1881841831            0.00            0.00        1   \n6362617             0.0  C1365125890        68488.84      6379898.11        1   \n6362618             0.0  C2080388513            0.00            0.00        1   \n6362619             0.0   C873221189      6510099.11      7360101.63        1   \n\n         isFlaggedFraud  \n6362615               0  \n6362616               0  \n6362617               0  \n6362618               0  \n6362619               0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>step</th>\n      <th>type</th>\n      <th>amount</th>\n      <th>nameOrig</th>\n      <th>oldbalanceOrg</th>\n      <th>newbalanceOrig</th>\n      <th>nameDest</th>\n      <th>oldbalanceDest</th>\n      <th>newbalanceDest</th>\n      <th>isFraud</th>\n      <th>isFlaggedFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6362615</th>\n      <td>743</td>\n      <td>CASH_OUT</td>\n      <td>339682.13</td>\n      <td>C786484425</td>\n      <td>339682.13</td>\n      <td>0.0</td>\n      <td>C776919290</td>\n      <td>0.00</td>\n      <td>339682.13</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6362616</th>\n      <td>743</td>\n      <td>TRANSFER</td>\n      <td>6311409.28</td>\n      <td>C1529008245</td>\n      <td>6311409.28</td>\n      <td>0.0</td>\n      <td>C1881841831</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6362617</th>\n      <td>743</td>\n      <td>CASH_OUT</td>\n      <td>6311409.28</td>\n      <td>C1162922333</td>\n      <td>6311409.28</td>\n      <td>0.0</td>\n      <td>C1365125890</td>\n      <td>68488.84</td>\n      <td>6379898.11</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6362618</th>\n      <td>743</td>\n      <td>TRANSFER</td>\n      <td>850002.52</td>\n      <td>C1685995037</td>\n      <td>850002.52</td>\n      <td>0.0</td>\n      <td>C2080388513</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6362619</th>\n      <td>743</td>\n      <td>CASH_OUT</td>\n      <td>850002.52</td>\n      <td>C1280323807</td>\n      <td>850002.52</td>\n      <td>0.0</td>\n      <td>C873221189</td>\n      <td>6510099.11</td>\n      <td>7360101.63</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:16:11.590741Z",
     "start_time": "2024-05-18T11:16:11.508960Z"
    }
   },
   "id": "1709d63d72f54bb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(6362620, 11)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:16:11.590741Z",
     "start_time": "2024-05-18T11:16:11.550533200Z"
    }
   },
   "id": "b397047508d8575a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd6cbcd1ca3b3659"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Missing values\n",
    "There are several strategies for handling missing values, including removing rows or columns with missing values, filling missing values with a specific value, or using more advanced techniques like interpolation or modeling."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a29f03ff427a192"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step              0\n",
      "type              0\n",
      "amount            0\n",
      "nameOrig          0\n",
      "oldbalanceOrg     0\n",
      "newbalanceOrig    0\n",
      "nameDest          0\n",
      "oldbalanceDest    0\n",
      "newbalanceDest    0\n",
      "isFraud           0\n",
      "isFlaggedFraud    0\n",
      "dtype: int64\n",
      "step              0\n",
      "type              0\n",
      "amount            0\n",
      "nameOrig          0\n",
      "oldbalanceOrg     0\n",
      "newbalanceOrig    0\n",
      "nameDest          0\n",
      "oldbalanceDest    0\n",
      "newbalanceDest    0\n",
      "isFraud           0\n",
      "isFlaggedFraud    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Verify if there are any missing values left\n",
    "print(df.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:16:16.708270300Z",
     "start_time": "2024-05-18T11:16:11.570922900Z"
    }
   },
   "id": "877dfb731f81bd56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Handling Outliers\n",
    "Outliers can be identified and treated in various ways. One common method is to use the Interquartile Range (IQR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc1f503fa5f9592"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "count  6.362620e+06   6.362620e+06    6.362620e+06    6.362620e+06   \n",
      "mean   1.322667e+05   7.221247e+04    8.872275e+04    6.003940e+05   \n",
      "std    1.462368e+05   1.024141e+05    1.393412e+05    8.369711e+05   \n",
      "min    0.000000e+00   0.000000e+00    0.000000e+00    0.000000e+00   \n",
      "25%    1.338957e+04   0.000000e+00    0.000000e+00    0.000000e+00   \n",
      "50%    7.487194e+04   1.420800e+04    0.000000e+00    1.327057e+05   \n",
      "75%    2.087215e+05   1.073152e+05    1.442584e+05    9.430367e+05   \n",
      "max    5.017193e+05   2.682879e+05    3.606460e+05    2.357592e+06   \n",
      "\n",
      "       newbalanceDest  \n",
      "count    6.362620e+06  \n",
      "mean     7.150404e+05  \n",
      "std      9.673665e+05  \n",
      "min      0.000000e+00  \n",
      "25%      0.000000e+00  \n",
      "50%      2.146614e+05  \n",
      "75%      1.111909e+06  \n",
      "max      2.779773e+06  \n"
     ]
    }
   ],
   "source": [
    "# Function to detect and cap outliers using IQR\n",
    "def cap_outliers(df, feature):\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[feature] = np.where(df[feature] < lower_bound, lower_bound, df[feature])\n",
    "    df[feature] = np.where(df[feature] > upper_bound, upper_bound, df[feature])\n",
    "\n",
    "# List of numerical features\n",
    "features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Cap outliers in numerical features\n",
    "for feature in features:\n",
    "    cap_outliers(df, feature)\n",
    "\n",
    "# Verify by checking the descriptive statistics\n",
    "print(df[features].describe())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:16:22.513993300Z",
     "start_time": "2024-05-18T11:16:16.706926500Z"
    }
   },
   "id": "ca0ae955b405d37a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Multi-collinearity\n",
    "To handle multi-collinearity, we calculate the Variance Inflation Factor (VIF):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d667b09016d62926"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m vif_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[0;32m      6\u001B[0m vif_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[1;32m----> 7\u001B[0m vif_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVIF\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[43mvariance_inflation_factor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X\u001B[38;5;241m.\u001B[39mcolumns))]\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(vif_data)\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:196\u001B[0m, in \u001B[0;36mvariance_inflation_factor\u001B[1;34m(exog, exog_idx)\u001B[0m\n\u001B[0;32m    194\u001B[0m mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(k_vars) \u001B[38;5;241m!=\u001B[39m exog_idx\n\u001B[0;32m    195\u001B[0m x_noti \u001B[38;5;241m=\u001B[39m exog[:, mask]\n\u001B[1;32m--> 196\u001B[0m r_squared_i \u001B[38;5;241m=\u001B[39m \u001B[43mOLS\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_noti\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfit()\u001B[38;5;241m.\u001B[39mrsquared\n\u001B[0;32m    197\u001B[0m vif \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1.\u001B[39m \u001B[38;5;241m-\u001B[39m r_squared_i)\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m vif\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:924\u001B[0m, in \u001B[0;36mOLS.__init__\u001B[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[0;32m    921\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWeights are not supported in OLS and will be ignored\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    922\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn exception will be raised in the next version.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    923\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg, ValueWarning)\n\u001B[1;32m--> 924\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_keys:\n\u001B[0;32m    927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_keys\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:749\u001B[0m, in \u001B[0;36mWLS.__init__\u001B[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001B[0m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     weights \u001B[38;5;241m=\u001B[39m weights\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m--> 749\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    751\u001B[0m nobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    752\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:203\u001B[0m, in \u001B[0;36mRegressionModel.__init__\u001B[1;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 203\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpinv_wexog: Float64Array \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_attr\u001B[38;5;241m.\u001B[39mextend([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpinv_wexog\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwendog\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwexog\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001B[0m, in \u001B[0;36mLikelihoodModel.__init__\u001B[1;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 270\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialize()\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001B[0m, in \u001B[0;36mModel.__init__\u001B[1;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[0;32m     93\u001B[0m missing \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     94\u001B[0m hasconst \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhasconst\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m---> 95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m                              \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_constant \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mk_constant\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexog\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001B[0m, in \u001B[0;36mModel._handle_data\u001B[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_handle_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog, missing, hasconst, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 135\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mhandle_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001B[39;00m\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001B[0m, in \u001B[0;36mhandle_data\u001B[1;34m(endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[0;32m    672\u001B[0m     exog \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(exog)\n\u001B[0;32m    674\u001B[0m klass \u001B[38;5;241m=\u001B[39m handle_data_class_factory(endog, exog)\n\u001B[1;32m--> 675\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mklass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m             \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\base\\data.py:88\u001B[0m, in \u001B[0;36mModelData.__init__\u001B[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconst_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_constant \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 88\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_constant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhasconst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_integrity()\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cache \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mD:\\Users\\srish\\PycharmProjects\\Environments\\FraudDetection\\Lib\\site-packages\\statsmodels\\base\\data.py:133\u001B[0m, in \u001B[0;36mModelData._handle_constant\u001B[1;34m(self, hasconst)\u001B[0m\n\u001B[0;32m    131\u001B[0m check_implicit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    132\u001B[0m exog_max \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misfinite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexog_max\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MissingDataError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexog contains inf or nans\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    135\u001B[0m exog_min \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X = df.drop(columns=['isFraud'])\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:17:25.356809500Z",
     "start_time": "2024-05-18T11:17:09.652945200Z"
    }
   },
   "id": "621950ae92bb1446"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fraud Detection Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5254ff39fee6b60d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df['deltaOrig'] = df['newbalanceOrig'] - df['oldbalanceOrg']\n",
    "df['deltaDest'] = df['newbalanceDest'] - df['oldbalanceDest']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.456200400Z"
    }
   },
   "id": "a73913a093bf668c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['type'] = label_encoder.fit_transform(df['type'])\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "print(\"Data types of columns:\")\n",
    "print(df.dtypes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.456200400Z"
    }
   },
   "id": "34b747dec718470a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dropping non-numeric or non-relevant columns (if any)\n",
    "# Here, we assume 'nameOrig' and 'nameDest' are non-numeric identifiers that should be dropped\n",
    "df = df.drop(columns=['nameOrig', 'nameDest'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.456200400Z"
    }
   },
   "id": "488240edd08b0218"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X, y = df.drop(columns='isFraud'), df['isFraud']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.473892600Z"
    }
   },
   "id": "49a28f3ab25c8946"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Confirming the transformation\n",
    "print(\"First few rows of X_train after scaling:\")\n",
    "print(X_train[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.473892600Z"
    }
   },
   "id": "12683972649b227c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Naive Bayes\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1bc10113e231d4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.473892600Z"
    }
   },
   "id": "1c96812a1729d0b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.495180600Z"
    }
   },
   "id": "d7ef761748a36949"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Classification Report for Gaussian Naive Bayes\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:16:36.671585400Z",
     "start_time": "2024-05-18T11:16:36.497900500Z"
    }
   },
   "id": "95f9523930bb94d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix for Gaussian Naive Bayes\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.506950800Z"
    }
   },
   "id": "5f79770313c1e26a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae556d117cabd1bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred_lr = classifier.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.513255900Z"
    }
   },
   "id": "65b66b11296c61f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Classification Report for  Logistic Regression\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.521838900Z"
    }
   },
   "id": "2b2a9f0c762881da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix for Logistic Regression\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.523644400Z"
    }
   },
   "id": "a39e8a17ddfeffa7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Interpretation: Feature Importance (for Logistic Regression)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77b7e2dca7915fdb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = np.abs(classifier.coef_[0])\n",
    "feature_names = X.columns\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.title('Feature Importance (Logistic Regression)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.534789400Z"
    }
   },
   "id": "825c739107b28f13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. How Did You Select Variables to be Included in the Model?\n",
    "Variables were selected based on domain knowledge and exploratory data analysis:\n",
    "\n",
    "Transaction Amount: Large amounts might indicate fraud.\n",
    "Balance Changes: Sudden large changes in balances could be a sign of fraud.\n",
    "Transaction Type: Certain types of transactions might be more prone to fraud.\n",
    "Existing Features: Variables like old and new balances for both origin and destination accounts."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be9e3dd4b10587b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Demonstrate the Performance of the Model by Using Best Set of Tools\n",
    "We evaluate model performance using accuracy, precision, recall, F1-score, and confusion matrices:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a71e485b3f9dda2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performance metrics for GaussianNB\n",
    "print(\"GaussianNB Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Performance metrics for Logistic Regression\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.540160600Z"
    }
   },
   "id": "cf01758315b23cdf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fraud Detection Model Explanation\n",
    "\n",
    "### Introduction\n",
    " I used two classification algorithms: Gaussian Naive Bayes and Logistic Regression. These models were chosen for their simplicity, efficiency, and interpretability, making them suitable for initial fraud detection efforts.\n",
    "\n",
    "### Data Preprocessing\n",
    "Proper data preprocessing ensures the model's effectiveness. Here are the key steps:\n",
    "\n",
    "1. **Feature Engineering**:\n",
    "    Feature engineering involves creating new features from existing data to enhance the model's predictive power. I created two new features, `deltaOrig` and `deltaDest`, which represent the change in balance for the origin and destination accounts, respectively:\n",
    "\n",
    "    These features help the model understand the impact of each transaction on account balances, which is crucial for identifying unusual or suspicious activities.\n",
    "\n",
    "2. **Encoding Categorical Variables**:\n",
    "    The `type` column indicates the type of transaction and is categorical. Machine learning algorithms require numerical input, so I converted this column to numerical format using `LabelEncoder`:\n",
    "\n",
    "    Encoding ensures that the model can process the transaction types effectively.\n",
    "\n",
    "3. **Dropping Non-Numeric Columns**:\n",
    "    The dataset includes non-numeric identifiers (`nameOrig` and `nameDest`) which are not relevant for prediction. These columns were dropped:\n",
    "\n",
    "    Removing these columns reduces noise and focuses the model on the most relevant features.\n",
    "\n",
    "### Splitting the Data\n",
    "To train and evaluate the models, I split the dataset into training and testing sets. The training set comprises 60% of the data, while the testing set comprises 40%:\n",
    "\n",
    "Splitting the data ensures that the models are trained on one portion of the data and tested on another, providing an unbiased evaluation of model performance.\n",
    "\n",
    "### Feature Scaling\n",
    "Feature scaling standardizes the range of features, ensuring each feature contributes equally to the model's calculations. I used `StandardScaler` to achieve this:\n",
    "\n",
    "Scaling is essential for algorithms like Logistic Regression, which rely on the magnitude of features to make predictions.\n",
    "\n",
    "### Model Training and Evaluation\n",
    "I trained two models: Gaussian Naive Bayes and Logistic Regression. Hereâ€™s why these models were chosen and their respective evaluations:\n",
    "\n",
    "#### Gaussian Naive Bayes\n",
    "Gaussian Naive Bayes is a probabilistic classifier based on Bayes' Theorem, assuming the features follow a Gaussian (normal) distribution. It is simple, fast, and effective for binary classification problems.\n",
    "\n",
    "Results:\n",
    "- **Accuracy**: [Insert Accuracy]\n",
    "- **Classification Report**: [Insert detailed report]\n",
    "- **Confusion Matrix**: [Insert matrix]\n",
    "\n",
    "#### Logistic Regression\n",
    "Logistic Regression is a linear model for binary classification. It models the probability of the default class and is highly interpretable, which is valuable for understanding fraud patterns.\n",
    "\n",
    "Results:\n",
    "- **Accuracy**: [Insert Accuracy]\n",
    "- **Classification Report**: [Insert detailed report]\n",
    "- **Confusion Matrix**: [Insert matrix]\n",
    "\n",
    "### Result\n",
    "Both models offer insights into detecting fraudulent transactions. Gaussian Naive Bayes provides a baseline with its probabilistic approach, while Logistic Regression often delivers better performance due to its ability to model complex relationships between features. Further improvements can be achieved by addressing class imbalance, tuning hyperparameters, and using cross-validation to ensure robustness.\n",
    "\n",
    "By carefully preprocessing the data, engineering relevant features, and rigorously evaluating the models, this project demonstrates an effective approach to building a fraud detection system that can accurately identify suspicious transactions.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4689ce1b8d10cf73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. What Are the Key Factors That Predict Fraudulent Customer?\n",
    "Key factors include:\n",
    "\n",
    "Transaction Amount: Higher amounts may indicate fraud.\n",
    "Balance Changes: Large differences in balances.\n",
    "Transaction Type: Certain types (e.g., 'TRANSFER', 'CASH_OUT') could be more fraudulent.\n",
    "New Features: The engineered features like deltaOrig and deltaDest."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d2d0b4941a88bfa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Do These Factors Make Sense? If Yes, How? If Not, How Not?\n",
    "Yes, these factors make sense:\n",
    "\n",
    "Transaction Amount: Fraudsters often try to move large sums quickly.\n",
    "Balance Changes: Significant changes can signal fraudulent activities.\n",
    "Transaction Type: Fraudsters might prefer types of transactions that are quicker or harder to trace."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6f7f3f176eb3c78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. What Kind of Prevention Should Be Adopted While Company Update Its Infrastructure?\n",
    "The company should adopt the following preventive measures:\n",
    "\n",
    "Real-time Monitoring: Implement real-time transaction monitoring systems using the developed model.\n",
    "Enhanced Verification: Require additional verification for high-risk transactions.\n",
    "Anomaly Detection: Use anomaly detection systems to flag unusual transaction patterns.\n",
    "Regular Audits: Conduct regular audits of transaction logs to identify potential frauds."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8890d355256ede7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. Assuming These Actions Have Been Implemented, How Would You Determine If They Work?\n",
    "To determine if the preventive measures are effective:\n",
    "\n",
    "Track Fraud Rates: Monitor the rate of detected fraud over time.\n",
    "Customer Feedback: Collect feedback from customers regarding any false positives or negative experiences.\n",
    "Performance Metrics: Evaluate the performance metrics (accuracy, precision, recall) of the fraud detection model periodically.\n",
    "A/B Testing: Implement A/B testing to compare the performance of transactions with and without the new measures.\n",
    "By continuously monitoring these indicators, the company can assess the effectiveness of the implemented measures and make necessary adjustments to improve fraud detection and prevention."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55e9ea8f8c5e097a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-18T11:16:36.547176700Z"
    }
   },
   "id": "442d09a5a2d6ea96"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
